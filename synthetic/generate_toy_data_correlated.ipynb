{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate utility function with higher-order polynomial (Correlated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.distributions.log_normal as log_normal\n",
    "import torch.distributions.bernoulli as bernoulli \n",
    "from sklearn import model_selection\n",
    "from scipy.stats import norm, uniform\n",
    "import math \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility\n",
    "$V_j\\\\\n",
    "= b_{0j} + b_1 x_1 + b_2 x_2 + b_3 x_3\\\\\n",
    "= b_{0j} + b_1 x_1 + (a_0 + a_1z_1 + a_2z_2 + a_3z_3 + a_{12}z_1z_2 + a_{13}z_1z_3 + a_{23}z_2z_3) x_2 \\\\\n",
    "= b_{0j} + b_1 x_1 + (a_0 + z^T A_1 + z^T A_2 z) x_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1, x2, x3: inc, full, flex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateZ(N):\n",
    "    '''\n",
    "    Generate z=[z0,z1,z2] for N samples (income, full-time, flexible-schedule)\n",
    "    Return: Z (N, 3)\n",
    "    '''\n",
    "    # Define p(z1)\n",
    "    m_fulltime = bernoulli.Bernoulli(0.5) # full time prob = 0.5\n",
    "    \n",
    "    # Define p(z0|z1), p(z2|z1)\n",
    "    m_inc_fulltime = log_normal.LogNormal(torch.Tensor([np.log(0.5)]), 0.25)\n",
    "    m_inc = log_normal.LogNormal(torch.Tensor([np.log(0.25)]), 0.2)\n",
    "    m_flex_fulltime = bernoulli.Bernoulli(0.5)\n",
    "    m_flex = bernoulli.Bernoulli(0.5) #notice the change here \n",
    "    \n",
    "#     m_flex_fulltime = bernoulli.Bernoulli(0.3)\n",
    "#     m_flex = bernoulli.Bernoulli(0.8)\n",
    "    \n",
    "    z = torch.zeros(N,3) # z = (income, job, flex)\n",
    "    \n",
    "    # Draw job \n",
    "    z[:,1] = m_fulltime.sample(sample_shape=(N,)) # N by 1\n",
    "    \n",
    "    # Given z[:,1]=1: draw z[:,0](income), z[:,2] (flex)\n",
    "    ind = z[:,1]==1\n",
    "    ind_sum = ind.sum().item()\n",
    "    z[ind,0] = m_inc_fulltime.sample(sample_shape=(ind_sum,)).flatten()\n",
    "    z[ind,2] = m_flex_fulltime.sample(sample_shape=(ind_sum,)).flatten()\n",
    "    \n",
    "    # Given z[:,1]=0: draw z[:,0](income), z[:,2] (flex)\n",
    "    z[~ind,0] = m_inc.sample(sample_shape=(N-ind_sum,)).flatten()\n",
    "    z[~ind,2] = m_flex.sample(sample_shape=(N-ind_sum,)).flatten()\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_of_x(A0, A1, A2, Z):\n",
    "    '''\n",
    "    Compute value of time for N persons given person characteristics z (N,D)\n",
    "    Input:\n",
    "        A0, A1, A2: 0, 1st and 2nd order interaction coefficients\n",
    "        Z: person input (N,D)\n",
    "    Return:\n",
    "        vox: (N,1)\n",
    "    '''\n",
    "    vox = A0 + torch.matmul(Z,A1) + torch.diag(torch.matmul(torch.matmul(Z,A2), Z.transpose(0,1)))\n",
    "    return vox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bivariate_uniform(rho, size, min_u1, max_u1, min_u3, max_u3):\n",
    "    u1 = uniform.rvs(size=size)\n",
    "    n1 = norm.ppf(u1)\n",
    "    \n",
    "    u2 = uniform.rvs(size=size)\n",
    "    n2 = norm.ppf(u2)\n",
    "\n",
    "    n3 = rho * n1 - math.sqrt(1 - rho**2)*n2\n",
    "    u3 = norm.cdf(n3)\n",
    "    \n",
    "    # shift u1, u3 to range \n",
    "    u1 = shift_uniform(u1, min_u1, max_u1)\n",
    "    u3 = shift_uniform(u3, min_u3, max_u3)\n",
    "    \n",
    "    return u1, u3\n",
    "\n",
    "def shift_uniform(u, min_u, max_u):\n",
    "    return min_u + (max_u-min_u)*u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateX(vots, vowts, rho):\n",
    "    '''\n",
    "    Generate samples x incl intercept: (N,K+1,J) where J = 2\n",
    "        x[n] = \n",
    "            [0, 1\n",
    "             c0,c1\n",
    "             t0,t1\n",
    "             wt_0, wt_1]\n",
    "        c0, c1: cost in $\n",
    "        t0, t1: time in minutes \n",
    "        wt0, wt1: waiting time in minutes\n",
    "    Return: \n",
    "        X: (N, D, 2)\n",
    "    '''\n",
    "    D = 4 # including ASC\n",
    "    N = vots.size(0)\n",
    "    X = torch.zeros(N,D,2)\n",
    "    \n",
    "    # Generate t, wt, c for 2 alternatives (batch mode)\n",
    "    min_t = 5\n",
    "    max_t = 100\n",
    "    min_wt = 5\n",
    "    max_wt = 30\n",
    "\n",
    "    min_c = 0.2\n",
    "    max_c = 100\n",
    "\n",
    "    succeed = False\n",
    "    \n",
    "    while not succeed:\n",
    "        t0, wt0 = bivariate_uniform(rho, N, min_t, max_t, min_wt, max_wt)\n",
    "        t1, wt1 = bivariate_uniform(rho, N, min_t, max_t, min_wt, max_wt)\n",
    "        \n",
    "        c1_c0 = vots*(t1-t0) + vowts*(wt1-wt0) + torch.randn(N)*2\n",
    "        \n",
    "        ind1 = (c1_c0 <= 0) & (min_c-c1_c0 <= max_c)\n",
    "        ind2 = (c1_c0 > 0) & (min_c <= max_c-c1_c0)\n",
    "        \n",
    "        if (ind1 | ind2).sum()==N:\n",
    "            succeed = True\n",
    "    \n",
    "    c0 = torch.DoubleTensor(N)\n",
    "    c0[ind1] = (torch.distributions.uniform.Uniform(min_c-c1_c0, max_c).sample())[ind1]\n",
    "    c0[ind2] = (torch.distributions.uniform.Uniform(min_c, max_c-c1_c0).sample())[ind2]\n",
    "\n",
    "    c1 = c0 + c1_c0\n",
    "    \n",
    "    for n in range(N):\n",
    "        X[n] = torch.Tensor([0, 1, c0[n], c1[n], t0[n], t1[n], wt0[n], wt1[n]]).reshape(4,2)\n",
    "    \n",
    "    # check correlation\n",
    "    print(np.corrcoef(X[:,2,0], X[:,3,0]))\n",
    "    print(np.corrcoef(X[:,2,1], X[:,3,1]))\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "# rho = 0.8\n",
    "# X = generateX(vots, vowts, rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utility(asc0, asc1, X, vots, vowts):\n",
    "    '''\n",
    "    Input:\n",
    "        X: (N,K+1,J)\n",
    "        vots: (N)\n",
    "        vowts: (N)\n",
    "    Returns:\n",
    "        V: (N,J)\n",
    "    '''\n",
    "    N, K_plus_1, J = X.size()\n",
    "    K = K_plus_1-1\n",
    "    V = torch.zeros(N,J)\n",
    "    for n in range(N): \n",
    "        vot_n = vots[n].item()\n",
    "        vowt_n = vowts[n].item()\n",
    "        Bn = torch.Tensor([asc0, asc1, -1, -1, vot_n, vot_n, vowt_n, vowt_n]).reshape(K+1,2) #(K+1,J)\n",
    "        xn = X[n] # (K+1,J)\n",
    "        V[n] = (Bn*xn).sum(dim=0) # 1 by J\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateData(N, rho):\n",
    "    # generate personal characteristics\n",
    "    Z = generateZ(N) # N, D\n",
    "\n",
    "    # compute vot, vowt\n",
    "    vots = value_of_x(A0_time, A1_time, A2_time, Z) # N\n",
    "    vowts = value_of_x(A0_wait, A1_wait, A2_wait, Z)\n",
    "    \n",
    "    # generate alternative attributes (closer to the decision boundary, which is why we need vots, vowts)\n",
    "    X = generateX(vots, vowts, rho) # (N, K+1, J) = (N, 4, 2)\n",
    "\n",
    "    v = utility(asc0, asc1, X, vots, vowts)\n",
    "\n",
    "    p = torch.softmax(v, dim=1)\n",
    "    m = torch.distributions.categorical.Categorical(probs=p)\n",
    "    y = m.sample()\n",
    "    nll = F.nll_loss(input=torch.log(p),target=y)\n",
    "    acc = (y==p.argmax(1)).sum().float()/N\n",
    "    data = {\"x\": X, \n",
    "            \"z\": Z,\n",
    "            \"y\": y, \n",
    "            \"p\": p, \n",
    "            \"vots\": vots, \n",
    "            \"vowts\": vowts, \n",
    "            \"params\": params,\n",
    "            \"nll\": nll.item(), \n",
    "            \"acc\": acc.item(), \n",
    "            \"rho\": rho}\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASC\n",
    "asc0 = 0\n",
    "asc1 = -0.1\n",
    "\n",
    "# 0, 1st and 2nd order effect of z on time and waiting time\n",
    "A0_time = -0.1\n",
    "A1_time = torch.Tensor([-0.5, -0.1, 0.05])\n",
    "A2_time = torch.Tensor(\\\n",
    "                       [[ 0.0000, -0.2000,  0.0500],\n",
    "                        [ 0.0000,  0.0000,  0.1000],\n",
    "                        [ 0.0000,  0.0000,  0.0000]])\n",
    "\n",
    "A0_wait = -0.2\n",
    "A1_wait = torch.Tensor([-0.8, -0.3, 0.1])\n",
    "A2_wait = torch.Tensor(\\\n",
    "                       [[ 0.0000, -0.3000,  0.08],\n",
    "                        [ 0.0000,  0.0000,  0.3000],\n",
    "                        [ 0.0000,  0.0000,  0.0000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"asc0\": asc0,\n",
    "    \"asc1\": asc1,\n",
    "    \"b_time\": A0_time,\n",
    "    \"b_time_z1\": A1_time[0].item(),\n",
    "    \"b_time_z2\": A1_time[1].item(),\n",
    "    \"b_time_z3\": A1_time[2].item(),\n",
    "    \"b_time_z1z2\": A2_time[0,1].item(),\n",
    "    \"b_time_z1z3\": A2_time[0,2].item(),\n",
    "    \"b_time_z2z3\": A2_time[1,2].item(),\n",
    "    \"b_wait\": A0_wait,\n",
    "    \"b_wait_z1\": A1_wait[0].item(),\n",
    "    \"b_wait_z2\": A1_wait[1].item(),\n",
    "    \"b_wait_z3\": A1_wait[2].item(),\n",
    "    \"b_wait_z1z2\": A2_wait[0,1].item(),\n",
    "    \"b_wait_z1z3\": A2_wait[0,2].item(),\n",
    "    \"b_wait_z2z3\": A2_wait[1,2].item(),\n",
    "    \"A0_time\": A0_time,\n",
    "    \"A1_time\": A1_time,\n",
    "    \"A2_time\": A2_time,\n",
    "    \"A0_wait\": A0_wait,\n",
    "    \"A1_wait\": A1_wait,\n",
    "    \"A2_wait\": A2_wait,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(params, open(\"toy_data/params.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate dataï¼ˆtraining 10K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.57685338]\n",
      " [0.57685338 1.        ]]\n",
      "[[1.         0.57241442]\n",
      " [0.57241442 1.        ]]\n",
      "[[1.         0.56436369]\n",
      " [0.56436369 1.        ]]\n",
      "[[1.         0.58725546]\n",
      " [0.58725546 1.        ]]\n",
      "[[1.       0.582377]\n",
      " [0.582377 1.      ]]\n",
      "[[1.         0.58360106]\n",
      " [0.58360106 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(7)\n",
    "np.random.seed(12)\n",
    "\n",
    "N_train, N_dev, N_test = 10000, 2000, 2000\n",
    "rho = 0.6\n",
    "\n",
    "data_train = generateData(N_train, rho)\n",
    "data_dev = generateData(N_dev, rho)\n",
    "data_test = generateData(N_test, rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45944902300834656\n",
      "0.4684458374977112\n",
      "0.4511032700538635\n"
     ]
    }
   ],
   "source": [
    "print (data_train['nll'])\n",
    "print (data_dev['nll'])\n",
    "print (data_test['nll'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"train\": data_train, 'dev': data_dev, \"test\": data_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['rho']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "suffix = f\"_rho_{rho}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(data_train, open(f\"toy_data/train_10k{suffix}.pkl\",\"wb\"))\n",
    "pickle.dump(data_dev, open(f\"toy_data/dev_10k{suffix}.pkl\",\"wb\"))\n",
    "pickle.dump(data_test, open(f\"toy_data/test_10k{suffix}.pkl\",\"wb\"))\n",
    "pickle.dump(data, open(f\"toy_data/data_10k{suffix}.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate 100K training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(7)\n",
    "N_train, N_dev, N_test = 100000, 2000, 2000\n",
    "\n",
    "data_train = generateData(N_train)\n",
    "data_dev = generateData(N_dev)\n",
    "data_test = generateData(N_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (data_train['nll'])\n",
    "print (data_dev['nll'])\n",
    "print (data_test['nll'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"train\": data_train, 'dev': data_dev, \"test\": data_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(data_train, open(\"toy_data/train_100k.pkl\",\"wb\"))\n",
    "pickle.dump(data_dev, open(\"toy_data/dev_100k.pkl\",\"wb\"))\n",
    "pickle.dump(data_test, open(\"toy_data/test_100k.pkl\",\"wb\"))\n",
    "pickle.dump(data, open(\"toy_data/data_100k.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['x'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = data_train[\"z\"].numpy()\n",
    "x = data_train[\"x\"]\n",
    "y = data_train[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Describe z\n",
    "print (\"==Training Data (z)==\")\n",
    "\n",
    "# full-time, flexibile\n",
    "print (\"full-time, flexible\", ((z[:,1]==1) & (z[:,2]==1)).sum())\n",
    "print (\"full-time, not flexible\",((z[:,1]==1) & (z[:,2]==0)).sum())\n",
    "print( \"not full-time, flexible\", ((z[:,1]==0) & (z[:,2]==1)).sum())\n",
    "print (\"not full-time, not flexible\",((z[:,1]==0) & (z[:,2]==0)).sum())\n",
    "\n",
    "# income\n",
    "plt.hist(z[:,0]*60)\n",
    "plt.xlabel(\"Income ($ per hour)\")\n",
    "plt.savefig(\"toy_data/hist_income.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Describe z\n",
    "print (\"==Training Data (y)==\")\n",
    "\n",
    "# income \n",
    "plt.hist(z[:,0]*60)\n",
    "plt.xlabel(\"Income ($ per hour)\")\n",
    "plt.savefig(\"toy_data/hist_income.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost\n",
    "plt.hist(x[:,1,:].numpy())\n",
    "plt.xlabel(\"Cost ($)\")\n",
    "print (\"cost (min, max)=\", x[:,1,:].min(), x[:,1,:].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = sorted(x[:,1,:].flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time\n",
    "plt.hist(x[:,2,:].numpy())\n",
    "plt.xlabel(\"Time (min)\")\n",
    "print (\"time (min, max)=\", x[:,2,:].min(), x[:,2,:].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# waiting time\n",
    "plt.hist(x[:,2,:].numpy())\n",
    "plt.xlabel(\"Waiting Time (min)\")\n",
    "print (\"time (min, max)=\", x[:,3,:].min(), x[:,3,:].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot true VOT\n",
    "inc = torch.arange(0.0, 1.0, 0.02).reshape(-1,1)\n",
    "x_inc = (inc*60).tolist()\n",
    "n = len(inc)\n",
    "fulltime = torch.ones(n,1)\n",
    "nofulltime = torch.zeros(n,1)\n",
    "flex = torch.ones(n,1)\n",
    "noflex = torch.zeros(n,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_full_flex = torch.cat((inc,fulltime,flex),dim=1)\n",
    "z_full_noflex = torch.cat((inc,fulltime,noflex),dim=1)\n",
    "z_nofull_flex = torch.cat((inc,nofulltime,flex),dim=1)\n",
    "z_nofull_noflex = torch.cat((inc,nofulltime,noflex),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_vots = \\\n",
    "[value_of_x(A0_time, A1_time, A2_time, z_full_flex),\n",
    "value_of_x(A0_time, A1_time, A2_time, z_full_noflex),\n",
    "value_of_x(A0_time, A1_time, A2_time, z_nofull_flex),\n",
    "value_of_x(A0_time, A1_time, A2_time, z_nofull_noflex)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_vowts = \\\n",
    "[value_of_x(A0_wait, A1_wait, A2_wait, z_full_flex),\n",
    "value_of_x(A0_wait, A1_wait, A2_wait, z_full_noflex),\n",
    "value_of_x(A0_wait, A1_wait, A2_wait, z_nofull_flex),\n",
    "value_of_x(A0_wait, A1_wait, A2_wait, z_nofull_noflex)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_true = plt.figure()\n",
    "for e in true_vots:\n",
    "    plt.plot(x_inc,(-e*60).tolist())\n",
    "plt.legend(['full-time, flex', 'full-time, not flex', 'not full-time, flex', 'not full-time, not flex'])\n",
    "plt.xlabel(\"income ($ per hour)\")\n",
    "plt.ylabel(\"value of time ($ per hour)\")\n",
    "plt.ylim(0, 60)\n",
    "plt.title(\"Value of Time vs. Hourly Income (True)\")\n",
    "plt.savefig(\"toy_data/vot_true.png\", dpi=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_true = plt.figure()\n",
    "for e in true_vowts:\n",
    "    plt.plot(x_inc,(-e*60).tolist())\n",
    "plt.legend(['full-time, flex', 'full-time, not flex', 'not full-time, flex', 'not full-time, not flex'])\n",
    "plt.xlabel(\"income ($ per hour)\")\n",
    "plt.ylabel(\"value of waiting time ($ per hour)\")\n",
    "plt.ylim(0, 100)\n",
    "plt.title(\"Value of Waiting Time vs. Hourly Income (True)\")\n",
    "plt.savefig(\"toy_data/vowt_true.png\", dpi=250)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
